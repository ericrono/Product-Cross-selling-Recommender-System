{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Cross Selling Recommender System\n",
    "\n",
    "**Business Problem Statement:**\n",
    "\n",
    "Our financial services company has a diverse portfolio of investment products, yet the vast majority (99%) of our existing customers hold only one product—the Money Market Fund. Despite a broad array of offerings (Balanced Fund, Dollar Fund, Equity Fund, Fixed Income Fund, and Wealth Fund), our product penetration per customer (PPC) remains exceptionally low. This indicates a significant opportunity to cross-sell additional products to our existing customer base, which would increase customer value, loyalty, and the company’s overall profitability.\n",
    "\n",
    "Currently, our customers’ data includes key information that could be leveraged to tailor product recommendations. These data points include:\n",
    "- **Location (town)**\n",
    "- **Gender**\n",
    "- **Customer-relationship or beneficiary information** (as customers may have more than one relationship or beneficiary associated with them)\n",
    "- **Customer age and DOB**\n",
    "- **Beneficiary age and DOB**\n",
    "\n",
    "Our goal is to create a user-friendly, intelligent recommender system that can analyze this existing data to suggest additional, relevant financial products to each customer. This system should be able to identify patterns or trends in customer profiles, uncover customer needs, and map those needs to suitable financial products, increasing our PPC in an efficient, cost-effective manner. \n",
    "\n",
    "**Objectives:**\n",
    "1. **Customer Retention and Loyalty**: By offering personalized recommendations, we aim to build deeper, more personalized relationships with our customers, making them more likely to stay with us long-term.\n",
    "2. **Increased Revenue per Customer**: A successful cross-selling strategy would increase the average number of products per customer, boosting overall portfolio revenue.\n",
    "3. **User-Friendly Experience**: Ensuring a straightforward, accessible interface for customers to explore new financial products, particularly given that our target customers may have limited experience with financial diversification.\n",
    "\n",
    "**Project Success Criteria:**\n",
    "1. Develop a model that accurately predicts the next likely product(s) for each customer based on their profile and behavior.\n",
    "2. Achieve a measurable increase in the PPC rate by the end of the initial deployment phase.\n",
    "3. Design an intuitive interface that enhances the customer journey, with minimal friction, to encourage engagement and adoption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding:\n",
    "\n",
    "Our dataset comprises customer demographic and account information, which will serve as the foundation for building a cross-selling recommender system. By analyzing these features, we aim to uncover insights into customer behavior and needs, using patterns within the data to suggest relevant financial products. Key columns include identifiers, demographic data, and account-related features. Each attribute plays a role in shaping customer profiles, which will help guide product recommendations. Below is an overview of each column:\n",
    "\n",
    "1. **Member Number (`member_no`)**  \n",
    "   - A unique identifier for each customer.\n",
    "\n",
    "2. **Registration Date (`reg_date`)**  \n",
    "   - The date when the customer first registered with our company.\n",
    "\n",
    "3. **Date of Birth (`dob`)**  \n",
    "   - The customer’s date of birth, used to calculate age.\n",
    "\n",
    "4. **House Number (`hse_no`)**  \n",
    "   - The residential house number of the customer.\n",
    "\n",
    "5. **Gender (`gender`)**  \n",
    "   - The gender of the customer.\n",
    "\n",
    "6. **Town (`town`)**  \n",
    "   - The town or city of the customer’s residence.\n",
    "\n",
    "7. **Relationship (`relationship`)**  \n",
    "   - Indicates the relationship type with any listed beneficiaries.\n",
    "\n",
    "8. **Beneficiary Date of Birth (`beneficiery_dob`)**  \n",
    "   - The date of birth of a beneficiary associated with the customer.\n",
    "\n",
    "9. **Portfolio (`portfolio`)**  \n",
    "   - The financial products currently held by the customer.\n",
    "\n",
    "---\n",
    "\n",
    "### Data Considerations:\n",
    "\n",
    "**Data Completeness and Consistency**  \n",
    "   - Given the variety of data sources, ensure that each column is complete and uniformly formatted. Date fields like `dob`, `reg_date`, and `beneficiary_dob` must be consistent across the dataset, as inconsistencies could lead to inaccurate age and tenure calculations.\n",
    "\n",
    "**Multiple Beneficiaries**  \n",
    "   - Customers may have more than one beneficiary, creating potential complications in the data structure. Aggregate features, such as average or maximum beneficiary age, may be necessary to summarize information for modeling purposes.\n",
    "\n",
    "**Categorical Label Standardization**  \n",
    "   - Categorical features such as `gender`, `relationship`, and `town` should be standardized (e.g., no mixed casing or abbreviations) to ensure consistency. This will facilitate proper encoding for model input and avoid noise from variations in label text.\n",
    "\n",
    "**Imbalanced Product Holding**  \n",
    "   - With 99% of customers holding only the Money Market Fund, the portfolio data will be highly imbalanced. Careful sampling techniques and tailored evaluation metrics may be needed to prevent the model from being biased toward customers holding only this product.\n",
    "\n",
    "**Data Privacy and Sensitivity**  \n",
    "   - Sensitive data such as customer identification numbers, DOB, and financial product details require rigorous handling. Compliance with data privacy regulations is essential, and personal identifiers should be excluded from model features to maintain confidentiality.\n",
    "\n",
    "**Geographic Granularity**  \n",
    "   - Town data may vary in predictive value. Consider regional clustering or aggregation (e.g., grouping nearby towns or major regions) if individual town data proves to have limited relevance for model accuracy.\n",
    "\n",
    "**Tenure Calculation and Influence**  \n",
    "   - Calculating customer tenure from `reg_date` could help identify engagement level and readiness for cross-selling. Longer-tenure customers may be more open to new products, and segmentation based on tenure might reveal patterns in product uptake.\n",
    "\n",
    "**Beneficiary Relationships and Cross-Selling Opportunities**  \n",
    "   - Beneficiary data and relationship types could offer insights into cross-selling opportunities (e.g., suggesting long-term investment products for customers with young dependents). Analyzing these relationships is essential for creating a personalized recommendation approach.\n",
    "\n",
    "**Age Grouping and Demographic Segmentation**  \n",
    "   - Customer age, derived from `dob`, and beneficiary age could be grouped into segments to assess if specific age groups show higher receptivity to particular products. For example, older customers may favor fixed-income options, while younger ones might prefer equities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_no</th>\n",
       "      <th>reg_date</th>\n",
       "      <th>dob</th>\n",
       "      <th>hse_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>town</th>\n",
       "      <th>relationship</th>\n",
       "      <th>beneficiery_dob</th>\n",
       "      <th>portfolio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99996</td>\n",
       "      <td>2023-10-01 00:00:00.000</td>\n",
       "      <td>1998-04-06 00:00:00</td>\n",
       "      <td>Single Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>NAIROBI</td>\n",
       "      <td>Partner</td>\n",
       "      <td>1998-01-26</td>\n",
       "      <td>Money Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99996</td>\n",
       "      <td>2023-10-01 00:00:00.000</td>\n",
       "      <td>1998-04-06 00:00:00</td>\n",
       "      <td>Single Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>NAIROBI</td>\n",
       "      <td>Partner</td>\n",
       "      <td>1998-01-26</td>\n",
       "      <td>Money Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99996</td>\n",
       "      <td>2023-10-01 00:00:00.000</td>\n",
       "      <td>1998-04-06 00:00:00</td>\n",
       "      <td>Single Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>NAIROBI</td>\n",
       "      <td>Partner</td>\n",
       "      <td>1998-01-26</td>\n",
       "      <td>Money Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99996</td>\n",
       "      <td>2023-10-01 00:00:00.000</td>\n",
       "      <td>1998-04-06 00:00:00</td>\n",
       "      <td>Single Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>NAIROBI</td>\n",
       "      <td>Partner</td>\n",
       "      <td>1998-01-26</td>\n",
       "      <td>Money Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99996</td>\n",
       "      <td>2023-10-01 00:00:00.000</td>\n",
       "      <td>1998-04-06 00:00:00</td>\n",
       "      <td>Single Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>NAIROBI</td>\n",
       "      <td>Partner</td>\n",
       "      <td>1998-01-26</td>\n",
       "      <td>Money Market</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   member_no                 reg_date                  dob         hse_no  \\\n",
       "0      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
       "1      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
       "2      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
       "3      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
       "4      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
       "\n",
       "   gender     town relationship beneficiery_dob     portfolio  \n",
       "0  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
       "1  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
       "2  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
       "3  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
       "4  Female  NAIROBI      Partner      1998-01-26  Money Market  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('single_member.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7532954 entries, 0 to 7532953\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   member_no        int64 \n",
      " 1   reg_date         object\n",
      " 2   dob              object\n",
      " 3   hse_no           object\n",
      " 4   gender           object\n",
      " 5   town             object\n",
      " 6   relationship     object\n",
      " 7   beneficiery_dob  object\n",
      " 8   portfolio        object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 517.2+ MB\n",
      "\n",
      "First 5 rows:\n",
      "   member_no                 reg_date                  dob         hse_no  \\\n",
      "0      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
      "1      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
      "2      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
      "3      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
      "4      99996  2023-10-01 00:00:00.000  1998-04-06 00:00:00  Single Member   \n",
      "\n",
      "   gender     town relationship beneficiery_dob     portfolio  \n",
      "0  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
      "1  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
      "2  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
      "3  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
      "4  Female  NAIROBI      Partner      1998-01-26  Money Market  \n",
      "\n",
      "Basic statistics:\n",
      "          member_no\n",
      "count  7.532954e+06\n",
      "mean   3.669357e+04\n",
      "std    2.683964e+04\n",
      "min    2.000000e+00\n",
      "25%    1.404500e+04\n",
      "50%    3.167800e+04\n",
      "75%    5.540475e+04\n",
      "max    1.180110e+05\n",
      "\n",
      "Null values per column:\n",
      "member_no                0\n",
      "reg_date              1863\n",
      "dob                  20038\n",
      "hse_no                   0\n",
      "gender                4667\n",
      "town               1048216\n",
      "relationship       1632933\n",
      "beneficiery_dob    1086598\n",
      "portfolio                9\n",
      "dtype: int64\n",
      "\n",
      "Unique values per column:\n",
      "member_no          75513\n",
      "reg_date            3163\n",
      "dob                19092\n",
      "hse_no                 1\n",
      "gender                 6\n",
      "town                 973\n",
      "relationship         494\n",
      "beneficiery_dob    27488\n",
      "portfolio              7\n",
      "dtype: int64\n",
      "\n",
      "Gender distribution:\n",
      "gender\n",
      "Female    0.658931\n",
      "Male      0.339530\n",
      "F         0.001052\n",
      "M         0.000464\n",
      "MALE      0.000014\n",
      "FEMALE    0.000009\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Date range for reg_date:\n",
      "Min: 2022-03-04 00:00:00, Max: 2023-10-06 00:00:00\n",
      "\n",
      "Date range for dob:\n",
      "Min: 1934-01-01 00:00:00, Max: 2015-07-31 00:00:00\n",
      "\n",
      "Date range for beneficiery_dob:\n",
      "Min: 1694-12-26 00:00:00, Max: 2202-10-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataFrameInspector:\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initialize the DataFrameInspector with a file path.\n",
    "        Loads the data into a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.df = pd.read_csv('single_member.csv')\n",
    "\n",
    "    def display_info(self):\n",
    "        \"\"\"Display basic information about the DataFrame.\"\"\"\n",
    "        print(\"DataFrame Info:\")\n",
    "        self.df.info()\n",
    "\n",
    "    def show_head(self, n=5):\n",
    "        \"\"\"Show the first n rows of the DataFrame.\"\"\"\n",
    "        print(f\"\\nFirst {n} rows:\")\n",
    "        print(self.df.head(n))\n",
    "\n",
    "    def show_basic_stats(self):\n",
    "        \"\"\"Display summary statistics for numerical columns.\"\"\"\n",
    "        print(\"\\nBasic statistics:\")\n",
    "        print(self.df.describe())\n",
    "\n",
    "    def count_null_values(self):\n",
    "        \"\"\"Count the number of null values in each column.\"\"\"\n",
    "        print(\"\\nNull values per column:\")\n",
    "        print(self.df.isnull().sum())\n",
    "\n",
    "    def count_unique_values(self):\n",
    "        \"\"\"Count the number of unique values in each column.\"\"\"\n",
    "        print(\"\\nUnique values per column:\")\n",
    "        print(self.df.nunique())\n",
    "\n",
    "    def gender_distribution(self):\n",
    "        \"\"\"Show the distribution of gender values.\"\"\"\n",
    "        if 'gender' in self.df.columns:\n",
    "            print(\"\\nGender distribution:\")\n",
    "            print(self.df['gender'].value_counts(normalize=True))\n",
    "        else:\n",
    "            print(\"\\nGender column not found in dataset.\")\n",
    "\n",
    "    def date_range(self, column_name):\n",
    "        \"\"\"Display the range (min and max) of dates for a specific date column.\"\"\"\n",
    "        if column_name in self.df.columns:\n",
    "            self.df[column_name] = pd.to_datetime(self.df[column_name], errors='coerce')\n",
    "            print(f\"\\nDate range for {column_name}:\")\n",
    "            print(f\"Min: {self.df[column_name].min()}, Max: {self.df[column_name].max()}\")\n",
    "        else:\n",
    "            print(f\"\\n{column_name} column not found in dataset.\")\n",
    "\n",
    "    def inspect_all(self):\n",
    "        \"\"\"Run all inspection methods.\"\"\"\n",
    "        self.display_info()\n",
    "        self.show_head()\n",
    "        self.show_basic_stats()\n",
    "        self.count_null_values()\n",
    "        self.count_unique_values()\n",
    "        self.gender_distribution()\n",
    "        \n",
    "        # Check date ranges for specified date columns\n",
    "        self.date_range('reg_date')\n",
    "        self.date_range('dob')\n",
    "        self.date_range('beneficiery_dob')\n",
    "\n",
    "# Usage\n",
    "inspector = DataFrameInspector('your_dataset.csv')\n",
    "inspector.inspect_all()\n",
    "\n",
    "# Alternatively, call individual methods as needed\n",
    "# inspector.display_info()\n",
    "# inspector.show_head(10)  # Show first 10 rows\n",
    "# inspector.show_basic_stats()\n",
    "# inspector.count_null_values()\n",
    "# inspector.count_unique_values()\n",
    "# inspector.gender_distribution()\n",
    "# inspector.date_range('reg_date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset overview provides a snapshot of the data quality, distribution, and any potential data issues that might impact analysis or the development of a cross-selling recommender system. Here’s a breakdown of each key insight:\n",
    "\n",
    "### 1. **DataFrame Information**\n",
    "   - **Shape**: The dataset contains **7,532,954 rows and 9 columns**, which is a substantial dataset in terms of both rows and memory usage (~517.2 MB).\n",
    "   - **Data Types**: Only `member_no` is of integer type, while all other columns are objects (strings). Notably, date columns (`reg_date`, `dob`, `beneficiery_dob`) are stored as strings rather than date types, which may need conversion for time-based analysis.\n",
    "\n",
    "### 2. **Basic Statistics**\n",
    "   - **member_no**:\n",
    "     - The average value (`mean`) is **36,693.57**, and the **max** is **118,011**, indicating the range of member IDs.\n",
    "     - The minimum value is **2**, which could suggest an ID generation starting from low values.\n",
    "     - These stats mainly help confirm the range and spread of `member_no`, which is likely to serve as a unique identifier for individuals.\n",
    "\n",
    "### 3. **Null Values per Column**\n",
    "   - Several columns have notable missing values:\n",
    "     - **reg_date** has **1,863 missing values**. This could be important for time-based or recency-based analyses.\n",
    "     - **dob** has **20,038 missing values**. Missing date of birth information could limit age-related recommendations.\n",
    "     - **town** has a substantial **1,048,216 missing values** (over 13% of the dataset). Missing location data may impact region-specific recommendations.\n",
    "     - **relationship** has **1,632,933 missing values**. The `relationship` status might provide insights into family structures, which could be useful for cross-selling, so the extent of missing values may affect analysis.\n",
    "     - **beneficiery_dob** has **1,086,598 missing values**, which is considerable and could impact any beneficiary-related recommendations.\n",
    "     - **portfolio** has **9 missing values**. This is a small amount but may need to be addressed if portfolio type is crucial for targeting.\n",
    "\n",
    "### 4. **Unique Values per Column**\n",
    "   - **member_no**: There are **75,513 unique IDs**, indicating that some `member_no` entries have multiple rows. This may imply multiple products or relationships associated with each member.\n",
    "   - **reg_date** has **3,163 unique values**, suggesting members registered over a wide range of dates.\n",
    "   - **dob** has **19,092 unique values**, indicating some duplicate birth dates, which is common.\n",
    "   - **hse_no** has only **1 unique value**, meaning all entries have the same value (\"Single Member\"), which may be a default placeholder.\n",
    "   - **gender** shows **6 unique values**, indicating some inconsistencies or multiple formats (e.g., \"Female\" and \"FEMALE\").\n",
    "   - **town** and **relationship** have **973** and **494 unique values** respectively, suggesting a broad diversity in locations and relationships.\n",
    "   - **beneficiery_dob** has **27,488 unique values**, showing diversity but likely also duplication.\n",
    "   - **portfolio** has **7 unique values**, suggesting multiple product types.\n",
    "\n",
    "### 5. **Gender Distribution**\n",
    "   - The `gender` column shows some data quality issues with **6 unique values**:\n",
    "     - The expected values (\"Female\" and \"Male\") are the majority, comprising about 66% and 34%, respectively.\n",
    "     - Minor variations like \"F\", \"M\", \"MALE\", and \"FEMALE\" likely represent data entry inconsistencies. Cleaning these values to a standard format (\"Female\" and \"Male\") would improve analysis accuracy.\n",
    "\n",
    "### 6. **Date Ranges**\n",
    "   - **reg_date**:\n",
    "     - Range is from **March 4, 2022, to October 6, 2023**. This shows registration dates over about 1.5 years, which is relevant for recency analysis.\n",
    "   - **dob**:\n",
    "     - Range is from **January 1, 1934, to July 31, 2015**. The minimum value suggests older members, while the maximum indicates younger members, likely around 8 years old in 2023. This is useful for age segmentation.\n",
    "   - **beneficiery_dob**:\n",
    "     - The range spans from **December 26, 1694, to October 3, 2202**. The minimum and maximum dates indicate significant anomalies likely due to data entry errors or placeholder values. Dates outside a reasonable range (e.g., before 1900 or after 2023) may need correction or filtering for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "- **Data Quality**: Several columns (`gender`, `town`, `relationship`, `beneficiery_dob`) have issues with missing values or inconsistent entries, which may require cleaning.\n",
    "- **Date Columns**: Converting and cleaning date columns (e.g., `reg_date`, `dob`, `beneficiery_dob`) will be essential, especially for any analysis involving age, registration recency, or beneficiary relationships.\n",
    "- **ID Uniqueness**: `member_no` has duplicate entries, likely indicating multiple entries per member. Understanding this structure is key to correctly interpreting member-level data.\n",
    "- **Next Steps**:\n",
    "  - Standardize values in the `gender` column.\n",
    "  - Filter or clean outliers in `beneficiery_dob`.\n",
    "  - Address missing values, especially in `relationship`, `town`, and `dob`.\n",
    "\n",
    "This dataset overview gives a clear starting point for preparing the data, identifying areas for cleaning, and understanding the distribution of key attributes, all of which will enhance the quality of the cross-selling recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data CLeaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Process Outline for Numerical and Categorical Data\n",
    "\n",
    "Given that our dataset is composed of **Numerical** and **Categorical** columns, we'll tailor our cleaning process to handle each type effectively, ensuring the data is prepared for robust analysis and modeling.\n",
    "\n",
    "---\n",
    "\n",
    "### Data Cleaning Process Summary\n",
    "\n",
    "1. **Handle Missing Values**: Impute or drop missing data based on the importance of each column.\n",
    "\n",
    "2. **Verify and Convert Data Types**: Ensure numerical and categorical columns are in the correct format.\n",
    "\n",
    "3. **Outlier Treatment**: Identify and correct outliers in numerical data, and standardize categorical entries.\n",
    "\n",
    "4. **Standardization and Encoding**: Normalize numerical values and encode categorical variables for modeling.\n",
    "\n",
    "5. **Final Validation**: Check for remaining inconsistencies and summarize the cleaned dataset's quality.\n",
    "\n",
    "This structured approach will ensure that our dataset’s **Numerical** and **Categorical** columns are fully prepared for analysis, facilitating reliable insights and model performance in the cross-selling recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.1 : Handle Missing Values: Impute or drop missing data based on the importance of each column.**\n",
    "\n",
    "Lets first have a look at the missing values in all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "                 Missing Values  Percentage (%)\n",
      "reg_date                   1863        0.024731\n",
      "dob                       20038        0.266005\n",
      "gender                     4667        0.061954\n",
      "town                    1048216       13.915072\n",
      "relationship            1632933       21.677193\n",
      "beneficiery_dob         1086598       14.424594\n",
      "portfolio                     9        0.000119\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_missing_values(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Prints the number and percentage of missing values for each column in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to inspect.\n",
    "    \"\"\"\n",
    "    # Calculate the number of missing values per column\n",
    "    missing_counts = df.isnull().sum()\n",
    "    \n",
    "    # Calculate the percentage of missing values per column\n",
    "    missing_percentage = (missing_counts / len(df)) * 100\n",
    "    \n",
    "    # Combine both series into a DataFrame for easier viewing\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Values': missing_counts,\n",
    "        'Percentage (%)': missing_percentage\n",
    "    })\n",
    "    \n",
    "    # Filter to show only columns with missing values\n",
    "    missing_df = missing_df[missing_df['Missing Values'] > 0]\n",
    "    \n",
    "    print(\"Missing values per column:\")\n",
    "    print(missing_df)\n",
    "\n",
    "print_missing_values(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
